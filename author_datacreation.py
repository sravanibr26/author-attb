# -*- coding: utf-8 -*-
"""Author_dataCreation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l_mwpvCzfxoJRQBh8TPsnnLzqcBEAlnI
"""

from nltk import tokenize
import numpy as np
import random
import pandas as pd
import nltk
nltk.download('punkt')

def split_text(filepath, min_char):

    # Load data into string variable and remove new line characters
    file = open(filepath, "r", encoding="utf8")
    text = file.read().replace('\n', ' ')
    text = text.replace('.”', '”.').replace('."', '".').replace('?”', '”?').replace('!”', '”!')
    text = text.replace('--', ' ').replace('. . .', '').replace('_', '')
    file.close()

    # Split text into a list of sentences
    sentences = tokenize.sent_tokenize(text)

    # Remove sentences that are less than min_char long
    sentences = [sent for sent in sentences if len(sent) >= min_char]

    return list(sentences)

# Set parameter values
min_char = 5

# Create lists

charles_dickens = split_text('/content/The_Battle_of_Life.txt', min_char = min_char)

jane_austen = split_text('/content/Love_and_Freindship_[sic].txt', min_char = min_char)

jonathan_swift = split_text('/content/A_Tale_of_a_Tub.txt', min_char = min_char)

lewis_caroll = split_text('/content/A_Tangled_Tale.txt', min_char = min_char)

mark_twain = split_text('/content/A_Double_Barrelled_Detective_Story.txt', min_char = min_char)

oscar_wilde = split_text('/content/A_House_of_Pomegranates.txt', min_char = min_char)

robert_louis_stevenson = split_text('/content/An_Inland_Voyage.txt', min_char = min_char)

rudyard_kipling = split_text('/content/The_City_of_Dreadful_Night.txt', min_char = min_char)

william_shakespeare = split_text('/content/Julius_Ceaser.txt', min_char = min_char)

# Print length of each list

text_dict = {'Charles Dickens': charles_dickens, 'Jane Austen': jane_austen,'Jonathan Swift': jonathan_swift, 'Lewis Caroll': lewis_caroll, 'Mark_Twain': mark_twain,'Oscar Wilde': oscar_wilde,'Robert Louis Stevenson': robert_louis_stevenson,'Rudyard Kipling': rudyard_kipling,'William Shakespeare': william_shakespeare}

for key in text_dict.keys():
    print(key, ':', len(text_dict[key]))

# Set random seed
np.random.seed(1)

# Set length parameter
max_len = 1000

# Select sentences
names = [charles_dickens, jane_austen, jonathan_swift, lewis_caroll, mark_twain, oscar_wilde, robert_louis_stevenson, rudyard_kipling, william_shakespeare]
combined = []

for name in names:
    name = np.random.choice(name, max_len, replace = False)
    combined += list(name)

print('The length of the combined list is:', len(combined))

labels = ['Charles Dickens']*max_len + ['Jane Austen']*max_len + ['Jonathan Swift']*max_len + ['Lewis Caroll']*max_len +  ['Mark_Twain']*max_len + ['Oscar Wilde']*max_len + ['Robert Louis Stevenson']*max_len + ['Rudyard Kipling']*max_len + ['William Shakespeare']*max_len

print('The length of the labels list is:', len(labels))

# Set random seed
random.seed(3)

# Randomly shuffle data
zipped = list(zip(combined, labels))
random.shuffle(zipped)
combined, labels = zip(*zipped)

# Create pandas dataframe
out_data = pd.DataFrame()
out_data['text'] = combined
out_data['author'] = labels

print(out_data.head())

# Export as a csv file
out_data.to_csv('us.csv', index=False)